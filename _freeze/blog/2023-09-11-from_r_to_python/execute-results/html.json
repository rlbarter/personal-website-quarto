{
  "hash": "14057f900eef6696c61ee174507e1693",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An introduction to Python for R Users\"\nauthor: \"Rebecca Barter\"\nformat:\n  html:\n    toc: true\n    toc-location: left\ncategories: [python]\ndate: 2023-09-12\nimage: img/python/rubaitul-azad-ZIPFteu-R8k-unsplash.jpg\ndescription: \"I have a confession to make: I am now a Python user. Don't judge me, join me! In this post, I introduce Python for data analysis from the perspective of an R (tidyverse) user. This post is a must-read if you are an R user hoping to dip your toes in the Python pool.\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n![](img/python/rubaitul-azad-ZIPFteu-R8k-unsplash.jpg){fig-alt='The python logo on a floating disc'}\n\nI have a confession to make: I am now a Python user. To be fair, I've used Python here and there over the years, but it was never my primary language (that has always been R). This year was the first time I had to actually sit down and really *use* Python for real projects. In fact, not only did I have to use Python, but I also had to *teach* Python. For those of you who teach, you'll know that the best way to make sure you know something really well is to teach it. The end result is that I now consider myself a Python user. (But don't worry, I'm still an R Lady at heart.) \n\nWhy did I decide to learn Python? I've been using R my whole data science life, and while I still think that R (with the tidyverse) is still the best language for data wrangling and data visualization, there is no denying that as a data scientist these days, Python is a required skill. If you're doing machine learning, Python is still light-years ahead of R. If you're working with software engineers, they're going to be much happier working with you if you use Python. If you're looking for a job, you're going to be much more employable if you're already comfortable with Python. \n\nWhile there are certainly similarities between R and Python, don't assume that knowing how to use one will automatically mean that you know how to use the other. That said, already knowing R does mean that the learning curve for learning Python won't be too steep (but it will still take a few months of regular use to reach competence).\n\nIn this post, I'm going to introduce you to the world of data analysis with Python from an R perspective. Obviously this post won't be exhaustive, but if you're a tidyverse R user who is looking to learn Python, this post can hopefully serve as a helpful launching point and will provide some relatable context on your Python journey.\n\nNote that this blog post will focus on *working with data* in Python using **pandas**. I won't be talking too much about things like SciPy, arrays, or scikit-learn here.\n\n## Helpful resources\n\nThere are a lot of resources out there for learning Python. The one that I found most useful was Wes McKinney's [Python for Data Analysis](https://wesmckinney.com/book/) book (Wes is the creator of pandas). There is a lot of information in there, and to be fair, you can skip a lot of it when you're starting out (like the stuff about sets, tuples, and arrays). These are important things to know about to be a well-rounded Python programmer, but for just doing simple data analysis with pandas data frames, these needn't be the focus.\n\n## Installing Python and VS Code\n\nManaging Python installations on my computer used to give me a headache. While I used to use Python in Jupyter notebooks via the Jupyter notebook IDE installed using anaconda, I've found that the simplest approach to getting Python up and running is now to [install the latest version of Python directly from the python website](https://www.python.org/downloads/) and [install the Visual Studio Code IDE](https://code.visualstudio.com/). Then you can select your preferred python installation within VS code and you're good to go. (You might want to watch a couple of YouTube videos to get started with VS code if you've never seen it before. It definitely took me a minute to orient myself.)\n\n### Jupyter notebooks\n\nWhile, these days, you can use Python together with quarto within RStudio, this isn't really what Python users do (yet...). So if you want to fit in with the cool Python kids, I'd recommend working with Jupyter notebooks (.ipynb files) *in the Visual Studio Code IDE*. You can install a jupyter notebook extension within the VS Code IDE (fortunately, there is *no need* to install jupyter notebooks or anaconda separately).\n\n\n## Libraries\n\nLike R, Python is mostly useful for data science because of the add-on libraries that some very smart people wrote to help us work with data. The main python libraries you'll need to start with are *NumPy* and *pandas*.\n\n\n### Installing libraries\n\nLike with R, you need to install a library before you can use it. \n\nThere are many ways to install python libraries, but if you installed python in the same way that I did above, the way that I usually install libraries is in the *terminal on my computer*, where I write:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npython3 -m pip install pandas\n```\n:::\n\n\nwhich will install the pandas library, for example. You may have a different preferred way of installing python libraries. That's fine. Your way is probably better than mine.\n\n\n\n### Loading libraries\n\n\nOne difference between R and Python is that once you have loaded a package into R, you can use the functions from the package without having to specify which library the package comes from every time you use it like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# I can use `filter()` from dplyr without having to specify that it comes from dplyr\nfilter(iris, Species == \"virginica\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1           6.3         3.3          6.0         2.5 virginica\n2           5.8         2.7          5.1         1.9 virginica\n3           7.1         3.0          5.9         2.1 virginica\n4           6.3         2.9          5.6         1.8 virginica\n5           6.5         3.0          5.8         2.2 virginica\n6           7.6         3.0          6.6         2.1 virginica\n7           4.9         2.5          4.5         1.7 virginica\n8           7.3         2.9          6.3         1.8 virginica\n9           6.7         2.5          5.8         1.8 virginica\n10          7.2         3.6          6.1         2.5 virginica\n11          6.5         3.2          5.1         2.0 virginica\n12          6.4         2.7          5.3         1.9 virginica\n13          6.8         3.0          5.5         2.1 virginica\n14          5.7         2.5          5.0         2.0 virginica\n15          5.8         2.8          5.1         2.4 virginica\n16          6.4         3.2          5.3         2.3 virginica\n17          6.5         3.0          5.5         1.8 virginica\n18          7.7         3.8          6.7         2.2 virginica\n19          7.7         2.6          6.9         2.3 virginica\n20          6.0         2.2          5.0         1.5 virginica\n21          6.9         3.2          5.7         2.3 virginica\n22          5.6         2.8          4.9         2.0 virginica\n23          7.7         2.8          6.7         2.0 virginica\n24          6.3         2.7          4.9         1.8 virginica\n25          6.7         3.3          5.7         2.1 virginica\n26          7.2         3.2          6.0         1.8 virginica\n27          6.2         2.8          4.8         1.8 virginica\n28          6.1         3.0          4.9         1.8 virginica\n29          6.4         2.8          5.6         2.1 virginica\n30          7.2         3.0          5.8         1.6 virginica\n31          7.4         2.8          6.1         1.9 virginica\n32          7.9         3.8          6.4         2.0 virginica\n33          6.4         2.8          5.6         2.2 virginica\n34          6.3         2.8          5.1         1.5 virginica\n35          6.1         2.6          5.6         1.4 virginica\n36          7.7         3.0          6.1         2.3 virginica\n37          6.3         3.4          5.6         2.4 virginica\n38          6.4         3.1          5.5         1.8 virginica\n39          6.0         3.0          4.8         1.8 virginica\n40          6.9         3.1          5.4         2.1 virginica\n41          6.7         3.1          5.6         2.4 virginica\n42          6.9         3.1          5.1         2.3 virginica\n43          5.8         2.7          5.1         1.9 virginica\n44          6.8         3.2          5.9         2.3 virginica\n45          6.7         3.3          5.7         2.5 virginica\n46          6.7         3.0          5.2         2.3 virginica\n47          6.3         2.5          5.0         1.9 virginica\n48          6.5         3.0          5.2         2.0 virginica\n49          6.2         3.4          5.4         2.3 virginica\n50          5.9         3.0          5.1         1.8 virginica\n```\n\n\n:::\n:::\n\n\nI could choose to explicitly specify that `filter()` comes from dplyr using `::` like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# I can explicitly specify that `filter()` comes from dplyr using `::`\ndplyr::filter(iris, Species == \"virginica\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1           6.3         3.3          6.0         2.5 virginica\n2           5.8         2.7          5.1         1.9 virginica\n3           7.1         3.0          5.9         2.1 virginica\n4           6.3         2.9          5.6         1.8 virginica\n5           6.5         3.0          5.8         2.2 virginica\n6           7.6         3.0          6.6         2.1 virginica\n7           4.9         2.5          4.5         1.7 virginica\n8           7.3         2.9          6.3         1.8 virginica\n9           6.7         2.5          5.8         1.8 virginica\n10          7.2         3.6          6.1         2.5 virginica\n11          6.5         3.2          5.1         2.0 virginica\n12          6.4         2.7          5.3         1.9 virginica\n13          6.8         3.0          5.5         2.1 virginica\n14          5.7         2.5          5.0         2.0 virginica\n15          5.8         2.8          5.1         2.4 virginica\n16          6.4         3.2          5.3         2.3 virginica\n17          6.5         3.0          5.5         1.8 virginica\n18          7.7         3.8          6.7         2.2 virginica\n19          7.7         2.6          6.9         2.3 virginica\n20          6.0         2.2          5.0         1.5 virginica\n21          6.9         3.2          5.7         2.3 virginica\n22          5.6         2.8          4.9         2.0 virginica\n23          7.7         2.8          6.7         2.0 virginica\n24          6.3         2.7          4.9         1.8 virginica\n25          6.7         3.3          5.7         2.1 virginica\n26          7.2         3.2          6.0         1.8 virginica\n27          6.2         2.8          4.8         1.8 virginica\n28          6.1         3.0          4.9         1.8 virginica\n29          6.4         2.8          5.6         2.1 virginica\n30          7.2         3.0          5.8         1.6 virginica\n31          7.4         2.8          6.1         1.9 virginica\n32          7.9         3.8          6.4         2.0 virginica\n33          6.4         2.8          5.6         2.2 virginica\n34          6.3         2.8          5.1         1.5 virginica\n35          6.1         2.6          5.6         1.4 virginica\n36          7.7         3.0          6.1         2.3 virginica\n37          6.3         3.4          5.6         2.4 virginica\n38          6.4         3.1          5.5         1.8 virginica\n39          6.0         3.0          4.8         1.8 virginica\n40          6.9         3.1          5.4         2.1 virginica\n41          6.7         3.1          5.6         2.4 virginica\n42          6.9         3.1          5.1         2.3 virginica\n43          5.8         2.7          5.1         1.9 virginica\n44          6.8         3.2          5.9         2.3 virginica\n45          6.7         3.3          5.7         2.5 virginica\n46          6.7         3.0          5.2         2.3 virginica\n47          6.3         2.5          5.0         1.9 virginica\n48          6.5         3.0          5.2         2.0 virginica\n49          6.2         3.4          5.4         2.3 virginica\n50          5.9         3.0          5.1         1.8 virginica\n```\n\n\n:::\n:::\n\n\nBut I don't need to.\n\nIn Python, however, you *do* need to specify which library the functions you are using come from, even after importing them. This is why every time you import a python library, you should give it a nickname so you don't have to type out the entire library name each time you want to use a function from it. Fortunately, there are some generally agreed-upon nicknames that everyone uses. E.g. pandas' nickname is \"pd\", and NumPy's nickname is \"np\". (In Python people usually say 'library' instead of 'package'.)\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib as plt\n```\n:::\n\n\nSo to use a function from the NumPy library, such as `log()`, you need to first specify the library nickname and then the function name, separated by a dot: `np.log()`. The following code will compute the logarithm of 7 using the `log()` function from the NumPy library whose nickname is `np`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnp.log(7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.9459101490553132\n```\n\n\n:::\n:::\n\n\n\nThat's another thing about Python: common mathematical functions like `log()`, `sqrt()`, and `exp()` all need to be imported from the NumPy library (unlike in R, where \"native\" versions of these functions exist).\n\n\n\n\n## Pandas data frames\n\nIn R, the building block of data science is the data frame. In Python, the building block of data science is also the DataFrame (but they spell it as one word with camel case). While R contains a native data frame, python's DataFrame comes from the \"pandas\" library (whose nickname is \"pd\"). \n\nIn R, we can create a toy data frame like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df <- data.frame(a = c(1, 2, 3, 4),\n                   b = c(5, 6, 7, 8))\nr_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a b\n1 1 5\n2 2 6\n3 3 7\n4 4 8\n```\n\n\n:::\n:::\n\n\nAnd in Python, we can create a toy DataFrame like this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df = pd.DataFrame({'a': [1,2,3,4], \n                          'b': [5,6,7,8]})\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n0  1  5\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n\nIn the R version above we provided *two* arguments to the `data.frame()` function, each of which contained an R vector (`c(1, 2, 3, 4)` and `c(5, 6, 7, 8)`) of the values that will form a column. The syntax for the python version, however, involves a *single argument* corresponding to a type of object called a **dictionary** (a dictionary is defined with curly brackets) whose named entries each contain a python **list** (`[1,2,3,4]` and `[5,6,7,8]`) of the values that will form a column.\n\n### Lists in python\n\nA **list** in python is actually a lot like a list in R, in that it can contain a variety of object types. Lists in python are created using square brackets:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmy_py_list = [1,'a',[3,4]]\nmy_py_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1, 'a', [3, 4]]\n```\n\n\n:::\n:::\n\n\nNote that in general, python users tend to use fewer spaces than R users, assignment is always done with `=` (there is no `<-` operator in python), and there is a general preference for single quotes `'` over double quotes `\"` (though I might have imagined that one).\n\nYou can change the first entry of a python list similarly to how you would do it in R, except that **python uses zero-indexing**, which means that the first entry is in position 0, the second entry is in position 1, and so on:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmy_py_list[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1\n```\n\n\n:::\n\n```{.python .cell-code}\nmy_py_list[0] = \"one\"\nmy_py_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['one', 'a', [3, 4]]\n```\n\n\n:::\n:::\n\n\n\n### Dictionaries\n\nA dictionary is kind of like a named list. In the example below, both of the entries in the dictionary are themselves lists:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmy_py_dict = {'name': ['Jane', 'Joe', 'Jerry'],\n              'age': [13, 15, 12]}\nmy_py_dict\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{'name': ['Jane', 'Joe', 'Jerry'], 'age': [13, 15, 12]}\n```\n\n\n:::\n:::\n\n\nBut while you cannot extract positional entries from it (`my_py_dict[0]` won't work), you can extract named entries:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmy_py_dict['name']\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['Jane', 'Joe', 'Jerry']\n```\n\n\n:::\n:::\n\n\nI can extract the first (position 0) entry from the `name` dict entry of `my_py_dict` as you would expect:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmy_py_dict['name'][0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'Jane'\n```\n\n\n:::\n:::\n\n\n\nThis is all super exciting, I'm sure, but I should probably point out that pretty much the only time I ever really use dictionaries is when I'm defining pandas DataFrames on the fly like I did above.\n\n\n\n### Column and row Indexing\n\nWhile both the R and python/pandas data frame have column names, the way you extract them is different. \n\nTo extract the column names from the R data frame, we would use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# print the R column names\ncolnames(r_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"a\" \"b\"\n```\n\n\n:::\n:::\n\n\nHowever, to extract the column names (or column *index*) from the pandas data frame, we use:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# print the pandas column names\npandas_df.columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIndex(['a', 'b'], dtype='object')\n```\n\n\n:::\n:::\n\n\nThe output of which is an \"index\" type object.\n\nThere are two main uses of the syntax `object.xyz`. The first, which is being used here, is used to extract an \"attribute\" `xyz` from an object (e.g., here we are extracting the `columns` attribute from the `pandas_df` DataFrame object).\n\nAnother \"attribute\" that you can extract from a DataFrame is the shape (which is equivalent to `dim()` in R):\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(4, 2)\n```\n\n\n:::\n:::\n\n\nThe `shape` output here has a \"tuple\" type (I won't go into tuples here because I'm afraid of them). \n\nAnother important attribute of a DataFrame is its row index:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.index\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRangeIndex(start=0, stop=4, step=1)\n```\n\n\n:::\n:::\n\n\nThis is a \"RangeIndex\" object that spans from 0 to 4 (*not inclusive*) with a step-size of 1 and corresponds to the row index of the DataFrame. \n\nBoth the column and row indexes of pandas DataFrames are special index objects that can be coerced to a python list using `list()` (which is a function in python for creating lists). \n\n\n::: {.cell}\n\n```{.python .cell-code}\nlist(pandas_df.index)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[0, 1, 2, 3]\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlist(pandas_df.columns)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['a', 'b']\n```\n\n\n:::\n:::\n\n\nWhenever python objects display weirdly, I try and convert them to something simpler, like a list, to see what they actually contain. Sometimes I even succeed.\n\n\n### Methods\n\nExtracting attributes is not the only use of the `object.xyz` dot syntax. Similar syntax also lets you apply object-specific *functions* to the object using the `object.fun()` dot syntax. \n\nNote that functions that are applied using the `object.fun()` (syntax where the function name comes after the dot) are called **methods**. These are functions that are specific to the type of object it is being applied to. \n\nFor example, we can apply the `mean()` and `sum()` DataFrame *methods* to our `pandas_df` DataFrame object to compute the mean and sum of each column in the data frame:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\na    2.5\nb    6.5\ndtype: float64\n```\n\n\n:::\n\n```{.python .cell-code}\npandas_df.sum()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\na    10\nb    26\ndtype: int64\n```\n\n\n:::\n:::\n\n\nNote that the output of these functions are pandas \"Series\" type objects, which is like a single column of a data frame. More on Series' objects below.\n\nIt is important to note that these `mean()` and `sum()` methods are not standalone functions. If we try to apply them to our DataFrame as we would do for regular functions, we get errors:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmean(pandas_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNameError: name 'mean' is not defined\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nsum(pandas_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n```\n\n\n:::\n:::\n\n\nSince they are \"methods\", these `mean()` and `sum()` method functions are specific to the DataFrame type object and must be applied using the `pandas_df.fun()` dot syntax. \n\nMoreover, since these method functions are specific to DataFrame objects, they also won't work on non-DataFrame objects, including lists:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npy_list = [1, 3, 4]\npy_list.mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAttributeError: 'list' object has no attribute 'mean'\n```\n\n\n:::\n:::\n\n\nSometimes the errors in Python are even helpful! Thanks Python!\n\nComing from R where a function is always just a function, this method vs function thing was quite confusing at first. Don't be scare. You'll get used to it. I hope. \n\n\n### Extracting columns\n\nWhile you can create a pandas DataFrame using a dictionary containing list entries (as we did earlier), the columns of a DataFrame themselves, when extracted, are a \"Series\" type object (rather than a list).\n\nFor example, the column `'a'` can be extracted using `[]`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df['a']\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    1\n1    2\n2    3\n3    4\nName: a, dtype: int64\n```\n\n\n:::\n:::\n\n\nwhich is the same as in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df[\"a\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a\n1 1\n2 2\n3 3\n4 4\n```\n\n\n:::\n:::\n\n\nNote that the columns of a DataFrame are also \"attributes\" of the data frame and can be extracted using the `df.col` dot syntax:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.a\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    1\n1    2\n2    3\n3    4\nName: a, dtype: int64\n```\n\n\n:::\n:::\n\n\nThe output above is the same as from the `pandas_df['a']` syntax: both outputs are a pandas Series object.\n\n\n\nWe can check the type of an object in python using the `type()` function:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntype(pandas_df['a'])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<class 'pandas.core.series.Series'>\n```\n\n\n:::\n:::\n\n\nwhich tells us that this column is a pandas \"Series\" object.\n\n### Series\n\nA pandas **Series** is like a one-dimensional DataFrame, and you can recognize that your object is a Series because there will be has two attributes printed out at the bottom: the `Name` (if indeed there is a name) and `dtype` (type). \n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df['a']\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    1\n1    2\n2    3\n3    4\nName: a, dtype: int64\n```\n\n\n:::\n:::\n\n\n\nA series object has a row index but no columns:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df['a'].index\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRangeIndex(start=0, stop=4, step=1)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df['a'].columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAttributeError: 'Series' object has no attribute 'columns'\n```\n\n\n:::\n:::\n\n\n### Adding columns to a DataFrame\n\nYou can add a column to a pandas DataFrame just as you would in base R:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df['c'] = [9,10,11,12]\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b   c\n0  1  5   9\n1  2  6  10\n2  3  7  11\n3  4  8  12\n```\n\n\n:::\n:::\n\n\n\nHowever, if you define a new DataFrame using an existing data frame and then modify it, e.g., by adding a new column:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# define a new data frame using the original one\npandas_df_new = pandas_df\n# add a new column to the new data frame\npandas_df_new['d'] = [13,14,15,16]\n# print out the new data frame\npandas_df_new\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b   c   d\n0  1  5   9  13\n1  2  6  10  14\n2  3  7  11  15\n3  4  8  12  16\n```\n\n\n:::\n:::\n\n\nNotice that the original DataFrame will also change:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b   c   d\n0  1  5   9  13\n1  2  6  10  14\n2  3  7  11  15\n3  4  8  12  16\n```\n\n\n:::\n:::\n\n\n**This is very different from what would happen in R**, where the `pandas_df_new` object would be a separate object from the original `pandas_df` object, and making modifications to the new object would not be reflected in the original one.\n\n### Don't forget to .copy()\n\nThis is because in python when you define a new object to be an existing object (`pandas_df_new = pandas_df`), you are actually creating a new \"pointer\" to the same underlying object being pointed to by the original name `pandas_df`. `pandas_df_new` becomes like an \"alias\" for `pandas_df`, rather than an entirely new object.\n\nTo avoid this issue, when defining a new DataFrame based on an existing DataFrame, you need to explicitly create a new object using the `copy()` method:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# redefine the original pandas DataFrame:\npandas_df = pd.DataFrame({'a': [1,2,3,4], \n                          'b': [5,6,7,8]})\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n0  1  5\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# define pandas_df_new as a \"copy\" of pandas_df:\npandas_df_new = pandas_df.copy()\npandas_df_new['c'] = [9,10,11,12]\npandas_df_new\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b   c\n0  1  5   9\n1  2  6  10\n2  3  7  11\n3  4  8  12\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# check that pandas_df did not change this time\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n0  1  5\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n\nThis issue of unintentionally creating an alias or a \"view\" of an object, rather than a new object itself is another confusing thing about python. You will undoubtedly run into issues with it when you're starting out (I certainly did). When in doubt, just `copy()`. \n\n### Filtering \n\n\nPandas Series objects act like vectors in R in that you can ask logical questions of them (*side-note: this does not work with python lists, but it does with with pandas Series objects*):\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# ask which entries in the column \"a\" are greater than 1\npandas_df['a'] > 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    False\n1     True\n2     True\n3     True\nName: a, dtype: bool\n```\n\n\n:::\n:::\n\n\nWhich is very similar to the R version:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ask which entries in the column \"a\" are greater than 1\nr_df[\"a\"] > 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         a\n[1,] FALSE\n[2,]  TRUE\n[3,]  TRUE\n[4,]  TRUE\n```\n\n\n:::\n:::\n\n\nIn base R, we can use this to \"filter\" our data frame to the rows where the condition above is true (the first row):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df[r_df[\"a\"] > 1, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a b\n2 2 6\n3 3 7\n4 4 8\n```\n\n\n:::\n:::\n\n\nThis syntax doesn't work for the pandas DataFrame, however, but if we make a few syntax modifications where we:\n\n1. employ the `.loc` method and \n\n1. provide `:` to the column dimension (which says to \"return all of the columns\"), \n\nthen we get the expected result:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.loc[pandas_df.a > 1,:]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n\nNote that `loc` isn't a normal function per se in that it is not followed by *round* parentheses `()`, but it is followed by the square indexing parentheses `[]`.\n\nIf we wanted to just return the second column, we would provide the second column's name (`'b'`) into the second dimension of the `.loc[,]` square parentheses.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.loc[pandas_df.a > 1,'b']\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1    6\n2    7\n3    8\nName: b, dtype: int64\n```\n\n\n:::\n:::\n\n\nHowever, `loc` expects either a Boolean series or a name in its index. The `iloc` method, on the other hand, takes *integer* index positions. The following code will extract the second, third, and fourth rows of the second column (remember zero-indexing!).\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.iloc[[1,2,3],1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1    6\n2    7\n3    8\nName: b, dtype: int64\n```\n\n\n:::\n:::\n\n\nAgain, the output is a pandas Series (as is almost always the case when the output of your code involves a single column).\n\nIt's a bit annoying that you can't use the same syntax to do both named (`.loc`) and integer (`.iloc`) indexing for pandas DataFrames, but such is life.\n\n\n#### The query() method\n\nSince this type of square bracket syntax for indexing feels clunky both in R and Python, you can alternatively use the `query()` method of a pandas DataFrame  similar to the `filter()` dplyr function in the tidyverse.\n\n\nRecall that with the pipe, the `filter()` syntax in R looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df |> filter(a > 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a b\n1 2 6\n2 3 7\n3 4 8\n```\n\n\n:::\n:::\n\n\n\nFor pandas DataFrame, the `query()` syntax looks like\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.query('a > 1')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n\nNote that there is no \"tidy eval\" in python, so you need to provide a quoted string (\"string\" is the python word for \"character\") argument to the `query()` method.\n\nIf you want to use an external variable, you need to access it using `@` within the query argument:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nthresh = 1\npandas_df.query('a > @thresh')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b\n1  2  6\n2  3  7\n3  4  8\n```\n\n\n:::\n:::\n\n\n\n### Grouping data frames\n\nOne of the most powerful parts of the tidyverse is the ability to perform grouped operations on data frames. For example, if we wanted to add a categorical column to our R data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add a new categorical column to r_df\nr_df[\"cat\"] = c(\"red\", \"red\", \"yellow\", \"yellow\")\nr_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  a b    cat\n1 1 5    red\n2 2 6    red\n3 3 7 yellow\n4 4 8 yellow\n```\n\n\n:::\n:::\n\n\nThen we could group by this new `cat` column and compute the mean of the values in column `a` in R as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df |> group_by(cat) |> summarize(mean_a = mean(a))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  cat    mean_a\n  <chr>   <dbl>\n1 red       1.5\n2 yellow    3.5\n```\n\n\n:::\n:::\n\n\nWe can do something very similar in Python with pandas DataFrames using the `groupby()` method. First, let's add a column of color categories to our pandas DataFrame:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# add a new categorical column to pandas_df\npandas_df[\"cat\"] = [\"red\",\"red\",\"yellow\",\"yellow\"]\npandas_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   a  b     cat\n0  1  5     red\n1  2  6     red\n2  3  7  yellow\n3  4  8  yellow\n```\n\n\n:::\n:::\n\n\nand then let's group the data frame by the new categorical column, extract the column \"a\", and then apply the mean method to the grouped column:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.groupby('cat')[\"a\"].mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncat\nred       1.5\nyellow    3.5\nName: a, dtype: float64\n```\n\n\n:::\n:::\n\n\nThe output is a Series object with the grouping variable values as the *row index*.\n\nNote that if we didn't extract the column \"a\", we would be applying grouped mean to all columns:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.groupby('cat').mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          a    b\ncat             \nred     1.5  5.5\nyellow  3.5  7.5\n```\n\n\n:::\n:::\n\n\nThe output is now a DataFrame with the grouping variable values as the row index.\n\n\n## Chaining functions together \n\nNote that python methods can be chained together using the `.` similarly to how we chain methods together in R using the pipe `|>`.\n\nFor instance, if we wanted to filter to rows where `a` was greater than 1, then group by the 'cat' column, and then compute the mean of the column `b`, we would do this in R as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_df |> filter(a > 1) |> group_by(cat) |> summarize(mean_b = mean(b))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  cat    mean_b\n  <chr>   <dbl>\n1 red       6  \n2 yellow    7.5\n```\n\n\n:::\n:::\n\n\nIn python, we do a similar thing, but using `.` instead of `|>`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.query('a > 1').groupby('cat')['b'].mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncat\nred       6.0\nyellow    7.5\nName: b, dtype: float64\n```\n\n\n:::\n:::\n\n\nNote that the code up to the `mean()` part results in a \"grouped Series\". Unlike in R, many objects in python don't always display nicely when called:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npandas_df.query('a > 1').groupby('cat')['b']\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<pandas.core.groupby.generic.SeriesGroupBy object at 0x11f377b50>\n```\n\n\n:::\n:::\n\n\n\nWe can use the `pd.Series()` function to force the grouped Series object back into a regular ungrouped Series (`pd.Series()` is used to define Series objects on the fly just as `pd.DataFrame()` is used to define DataFrames on the fly -- this is what I used at the beginning of this tutorial). \n\nLet's try to force the grouped Series object back into a regular pandas Series object:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.Series(pandas_df.query('a > 1').groupby('cat')['b'])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0          (red, [6])\n1    (yellow, [7, 8])\ndtype: object\n```\n\n\n:::\n:::\n\n\nThis Series contains tuples (I can tell from the round parentheses `()`), and I'm not going to lie, I'm afraid. But at least I can see what values the grouped Series contains. \n\n## Data visualization\n\n\nUnlike in R, where ggplot is the clear \"best\" way to create data visualizations (at least in my opinion), in python there are many different libraries for doing data visualization. The two you are most likely to have heard of include matplotlib and seaborn. \n\nSeaborn is a little prettier than matplotlib, but all I'm going to show in this tutorial is the inbuilt data visualization methods for pandas Series and DataFrame objects that are built on matplotlib.\n\n\nTo do some more interesting visualizations, let's load the gapminder dataset (from a URL) into a pandas DataFrame using the `pd.read_csv()` pandas function. This `pd.read_csv()` function can also be used to load a local .csv file.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngapminder = pd.read_csv(\"https://raw.githubusercontent.com/rlbarter/gapminder-data/main/gapminder.csv\")\n```\n:::\n\n\nLet's use the `head()` DataFrame method to look at the first 6 rows:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngapminder.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       country continent  year  lifeExp       pop   gdpPercap\n0  Afghanistan      Asia  1952   28.801   8425333  779.445314\n1  Afghanistan      Asia  1957   30.332   9240934  820.853030\n2  Afghanistan      Asia  1962   31.997  10267083  853.100710\n3  Afghanistan      Asia  1967   34.020  11537966  836.197138\n4  Afghanistan      Asia  1972   36.088  13079460  739.981106\n```\n\n\n:::\n:::\n\n\nLet's practice some of our new python skills. The following code will filter to the data for Australia and compute the mean life expectancy:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngapminder.query('country == \"Australia\"')['lifeExp'].mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n74.66291666666667\n```\n\n\n:::\n:::\n\n\nAnd the following will compute the average gdpPercap by continent:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_by_continent = gapminder.groupby('continent')['gdpPercap'].mean()\ngdp_by_continent\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncontinent\nAfrica       2193.754578\nAmericas     7136.110356\nAsia         7902.150428\nEurope      14469.475533\nOceania     18621.609223\nName: gdpPercap, dtype: float64\n```\n\n\n:::\n:::\n\n\nNotice that the output of this last piece of code is a Series object. Notice also that the (row) index is the continent:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_by_continent.index\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIndex(['Africa', 'Americas', 'Asia', 'Europe', 'Oceania'], dtype='object', name='continent')\n```\n\n\n:::\n:::\n\n\n\nWhat will happen if we apply the `plot()` method to this Series object?\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_by_continent.plot()\n```\n\n::: {.cell-output-display}\n![](2023-09-11-from_r_to_python_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n:::\n\n\nBy default a line plot is created and the row index is used as the x-axis labels by default. The DataFrame's `plot()` method here acts as a wrapper for the matplotlib library's plotting function. \n\nIf I wanted a bar chart instead of a line plot, I could create one using the `plot.bar()` method (instead of just the `plot()` method):\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_by_continent.plot.bar()\n```\n\n::: {.cell-output-display}\n![](2023-09-11-from_r_to_python_files/figure-html/unnamed-chunk-61-3.png){width=672}\n:::\n:::\n\n\nAgain, the row index of the Series object is used as the x-axis labels by default.\n\nWe could similarly create a scatterplot of the `gdpPercap` and `lifeExp` columns from `gapminder` using the `plot.scatter()` method:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngapminder.plot.scatter(x='gdpPercap', y='lifeExp')\n```\n\n::: {.cell-output-display}\n![](2023-09-11-from_r_to_python_files/figure-html/unnamed-chunk-62-5.png){width=672}\n:::\n:::\n\n\nWhile these built-in pandas plots are fine, I personally prefer the look of the seaborn library and the workflow of the plotly express library, neither of which I've covered in this post (and neither of which are as good as ggplot2 in my opinion). I recommend you look into both of these libraries (and more!) to figure out the data visualization workflow you prefer!\n\n## Wrapping up \n\nObviously, there's a lot more to learn about Python, but I'll leave it here for now. I hope this post has helped some of you R users get started on your Python journey!\n",
    "supporting": [
      "2023-09-11-from_r_to_python_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}