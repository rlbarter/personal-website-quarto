{"title":"The intuition behind inverse probability weighting in causal inference","markdown":{"yaml":{"title":"The intuition behind inverse probability weighting in causal inference","author":"Rebecca Barter","categories":["causal inference","statistics"],"date":"2017-07-05","format":{"html":{"toc":true,"toc-location":"left"}},"description":"Removing confounding can be done via a variety methods including IP-weighting. This post provides a summary of the intuition behind IP-weighting."},"headingText":"Confounding and idenitifiability","containsRefs":false,"markdown":"\n\nIn my [previous post](../2017-07-05-confounding/index.html), I introduced causal inference as a field interested in estimating the unobservable causal effects of a treatment: i.e. the difference between some measured outcome when the individual is assigned a treatment and the same outcome when the individual is not assigned the treatment.\n\n\n\nIf you'd like to quickly brush up on your causal inference, the fundamental issue associated with making causal inferences, and in particular, the troubles that arise in the presence of confounding, I suggest you read my [previous post](../2017-07-05-confounding/index.html) on this topic.\n\n\nRecall that the causal estimand is *identifiable* when (1) exchangeability/ignorability, (2) consistency and (3) positivity all hold. This means that the causal effect can be unbiasedly estimated using the estimand,\n$$\\hat{\\tau} = \\frac{1}{n_T}\\sum_{i : T_i = 1} y_i - \\frac{1}{n_C}\\sum_{i:T_i = 0}y_i.$$ \nwhere $n_T$ and $n_C$ are the number of individuals in the treated and control groups, respectively. This is the difference between the average treated and control outcomes.\n\n\n\nIn the presence of confounding, the exchangeability assumption is false, implying that the estimand above is not unbiased for the true population average causal effect.\n\nUnder the stronger condition of **conditional exchangeability**, wherein exchangeability holds within each strata of the confounding variables (i.e. $Y(1), Y(0) \\perp T | X$), then there are methods that can be used to eliminate confounding and estimate the causal effect.\n\n\nIn this post, I will discuss one such method, the inverse-probability method, for removing (or adjusting for) confounding.\n\nThe issue is that we can never truly know whether or not we have actually removed all confounding... but we will ignore this for now, and assume that we know each of the confounders in our data and that there are no unmeasured confounders.\n\n\n\n\n# Inverse probability weighting\n\nInverse-probability weighting removes confounding by creating a \"pseudo-population\" in which the treatment is independent of the measured confounders.\n\n\nWeighting procedures are not new, and have a long history being used in survey sampling. The idea of weighting observations in a survey sample is based on the idea that the sample surveyed is not quite representative of the broader population. The goal is to make the sample look more like the population. To do so, you can add a larger weight to the individuals who are underrepresented in the sample and a lower weight to those who are over-represented (e.g. if the population is 50% female, but your sample is only 35% female, you would add a larger weight to the female respondents). By the way to \"assign a weight\", \"re-weight\", or \"add a weight\" to an individual simply means to multiply their outcome by the weight in question.\n\nThis idea of re-weighting our sample in the context of estimating causal effects has a similar flavour, but it may take a bit of brain twisting to understand why, but let me phrase it as simply as I can in my current sleep deprived state:\n\n> Suppose that there are measurable differences between the control and treated groups. For example, perhaps younger males are much more likely to be in the treatment group than older males. Just because younger males are more likely to be in the treatment group, that doesn't mean that <u>all</u> younger males will be in the treatment group. Some of these younger males, even though they were very similar to their peers in every measurable way, ended up in the control group. In this case, it would make sense that comparing the outcome of these few young males in the control group with the outcome of the many young males in the treatment group serves as a fairly good estimate of the causal effect for the subgroup of young males. So we could up-weight the young males who were placed in the control group and down-weight the young males who, as expected, were placed in the treatment group.\n\n\n\nThis is the basic idea behind **inverse probability weighting**. Individuals who were assigned to the treatment group even though they were much more likely to be assigned to the control group are a rare, and valuable breed. We want to give their outcomes as much weight as possible, whereas the much larger group of individuals who were placed in the expected treatment group need less weight, simply because we have much more information on individuals like this.\n\n\nSuppose that there are two types of people. The first type has a 75% chance of receiving treatment, while the second type has only a 25% chance. If there are 4 people in each group, then we would expect that three of the people in the first group received treatment, while only one person from the second group would. If we wanted to estimate the causal effect (i.e. the difference in the average outcome between the first and second row), then it would be better if we could improve the treatment-control balance within each of the two treatment allocation groups. Thus, perhaps we could assign a weight of three to each of the single individuals in each group who were assigned to the less likely treatment class, (or alternatively a weight of 1/3 to each of the three individuals in each group who were assigned to the expected class).\n\nThis idea is demonstrated in the image below.\n\n```{r echo = FALSE, fig.align = \"center\"}\nknitr::include_graphics(\"img/causal-inference/propensity-weighting.png\")\n```\n\n\n\n\nAs implied by its name, inverse probability weighting literally refers to weighting the outcome measures by the inverse of the probability of the individual with a given set of covariates being assigned to their treatment (note that this doesn't depend on whether or not the individual *was* in fact assigned to treatment).This quantity is known as the **propensity score** and is denoted\n\n$$p(x) = P(T = 1 | X = x)$$\n\nFor treated individuals, we weight their outcome by\n$$w(x) = \\frac{1}{p(x)},$$\n\nwhereas for control individuals, the weight is:\n\n$$w(x) = \\frac{1}{1 - p(x)}$$\n\n\n\n\nObviously unless we randomly assigned treatment with a set probability (as in the example above), we do not actually know the propensity score of each individual. What we do observe however, is which individuals *were* actually assigned to treatment, along with a number of measured covariates for each individual. The idea is that we can use these covariates as well as our observation of who received treatment to develop a **logistic regression** model that predicts the probability of treatment (propensity score).\n\n\nThus, in the presence of measured confounders, we can estimate the causal effect by IP-weighting the original estimator:\n\n$$\\begin{align*}\n\\hat{\\tau}^{\\textrm{IP}} &= \\frac{1}{n_T}\\sum_{i : T_i = 1} \\frac{Y_i}{\\hat{p}(X_i)} - \\frac{1}{n_C}\\sum_{i:T_i = 0}\\frac{Y_i}{1 - \\hat{p}(X_i)} \\\\\n& = \\frac{1}{n}\\sum_i^n \\frac{T_iY_i}{\\hat{p}(X_i)} -  \\frac{1}{n}\\sum_i^n \\frac{(1 - T_i)Y_i}{1 - \\hat{p}(X_i)}.\n\\end{align*}$$ \n\nwhere $\\hat{p}(x)$ is a logistic-regression based estimator of the propensity score.\n\nTo show that this quantity is unbiased for the original quantity we want to estimate, $\\tau = E[Y(1)] - E[Y(0)]$, it is sufficient to show that\n\n$$E \\left[ \\frac{Y T}{p(X)}\\right] = E[Y(1)], ~~~~~ \\textrm{and} ~~~~~ E \\left[ \\frac{Y (1 - T)}{1 - p(X)}\\right] = E[Y(0)]$$\nwhich is easy to see as follows:\n\n$$\\begin{align*}\nE \\left[ \\frac{Y ~T}{p(X)}\\right] &= E \\left[ E \\left[ \\frac{Y T}{p(X) }\\Bigg| X\\right] \\right]\\\\\n& = E \\left[ E \\left[ \\frac{Y(1) ~T}{p(X)} \\Bigg|X\\right] \\right]\\\\\n& = E \\left[ \\frac{E [ Y(1) |X]~ E[T | X]}{p(X)} \\right]\\\\\n& = E \\left[E [ Y(1) |X] \\right]\\\\\n& = E \\left[ Y(1) \\right]\\\\\n\\end{align*}$$ \n\nand similarly for the second equality.\n\n\n\n## Standardized IP-weighting\n\n\nOne common issue with IP-weighting is that individuals with a propensity score very close to 0 (i.e. those extremely unlikely to be treated) will end up with a horrifyingly large weight, potentially making the weighted estimator highly unstable.\n\nA common alternative to the conventional weights that at least \"kind of\" addresses this problem are the **stabilized weights**, which use the marginal probability of treatment instead of $1$ in the weight numerator.\n\nFor treated individuals, the stabilized weight is given by\n\n$$w(x) = \\frac{P(T = 1)}{p(x)} = \\frac{P(T = 1)}{P(T = 1 | X = x)}$$\n\nand for control individuals, the stabilized weight is \n$$w(x) = \\frac{1 - P(T = 1)}{1 - p(x)} = \\frac{1 - P(T = 1)}{1 - P(T = 1 | X = x)}$$\n\nNote that whereas the original weights essentially [doubles the sample size](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4351790/), these stabilized weights preserve the sample size.\n\n# Resources\n\nMuch of the information provided in this post can be found in the [Causal Inference book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) by Miguel A. Hernan and James M. Robins.\n\nAdditional resources are the books *Causal Inference for Statistics, Social, and Biomedical Sciences* by Guido W. Imbens and Donald B. Rubin, and *Mostly Harmless Econometrics* by Joshua D. Angrist and J&ouml;rn-Steffen Pischke.\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\nIn my [previous post](../2017-07-05-confounding/index.html), I introduced causal inference as a field interested in estimating the unobservable causal effects of a treatment: i.e. the difference between some measured outcome when the individual is assigned a treatment and the same outcome when the individual is not assigned the treatment.\n\n\n\nIf you'd like to quickly brush up on your causal inference, the fundamental issue associated with making causal inferences, and in particular, the troubles that arise in the presence of confounding, I suggest you read my [previous post](../2017-07-05-confounding/index.html) on this topic.\n\n# Confounding and idenitifiability\n\nRecall that the causal estimand is *identifiable* when (1) exchangeability/ignorability, (2) consistency and (3) positivity all hold. This means that the causal effect can be unbiasedly estimated using the estimand,\n$$\\hat{\\tau} = \\frac{1}{n_T}\\sum_{i : T_i = 1} y_i - \\frac{1}{n_C}\\sum_{i:T_i = 0}y_i.$$ \nwhere $n_T$ and $n_C$ are the number of individuals in the treated and control groups, respectively. This is the difference between the average treated and control outcomes.\n\n\n\nIn the presence of confounding, the exchangeability assumption is false, implying that the estimand above is not unbiased for the true population average causal effect.\n\nUnder the stronger condition of **conditional exchangeability**, wherein exchangeability holds within each strata of the confounding variables (i.e. $Y(1), Y(0) \\perp T | X$), then there are methods that can be used to eliminate confounding and estimate the causal effect.\n\n\nIn this post, I will discuss one such method, the inverse-probability method, for removing (or adjusting for) confounding.\n\nThe issue is that we can never truly know whether or not we have actually removed all confounding... but we will ignore this for now, and assume that we know each of the confounders in our data and that there are no unmeasured confounders.\n\n\n\n\n# Inverse probability weighting\n\nInverse-probability weighting removes confounding by creating a \"pseudo-population\" in which the treatment is independent of the measured confounders.\n\n\nWeighting procedures are not new, and have a long history being used in survey sampling. The idea of weighting observations in a survey sample is based on the idea that the sample surveyed is not quite representative of the broader population. The goal is to make the sample look more like the population. To do so, you can add a larger weight to the individuals who are underrepresented in the sample and a lower weight to those who are over-represented (e.g. if the population is 50% female, but your sample is only 35% female, you would add a larger weight to the female respondents). By the way to \"assign a weight\", \"re-weight\", or \"add a weight\" to an individual simply means to multiply their outcome by the weight in question.\n\nThis idea of re-weighting our sample in the context of estimating causal effects has a similar flavour, but it may take a bit of brain twisting to understand why, but let me phrase it as simply as I can in my current sleep deprived state:\n\n> Suppose that there are measurable differences between the control and treated groups. For example, perhaps younger males are much more likely to be in the treatment group than older males. Just because younger males are more likely to be in the treatment group, that doesn't mean that <u>all</u> younger males will be in the treatment group. Some of these younger males, even though they were very similar to their peers in every measurable way, ended up in the control group. In this case, it would make sense that comparing the outcome of these few young males in the control group with the outcome of the many young males in the treatment group serves as a fairly good estimate of the causal effect for the subgroup of young males. So we could up-weight the young males who were placed in the control group and down-weight the young males who, as expected, were placed in the treatment group.\n\n\n\nThis is the basic idea behind **inverse probability weighting**. Individuals who were assigned to the treatment group even though they were much more likely to be assigned to the control group are a rare, and valuable breed. We want to give their outcomes as much weight as possible, whereas the much larger group of individuals who were placed in the expected treatment group need less weight, simply because we have much more information on individuals like this.\n\n\nSuppose that there are two types of people. The first type has a 75% chance of receiving treatment, while the second type has only a 25% chance. If there are 4 people in each group, then we would expect that three of the people in the first group received treatment, while only one person from the second group would. If we wanted to estimate the causal effect (i.e. the difference in the average outcome between the first and second row), then it would be better if we could improve the treatment-control balance within each of the two treatment allocation groups. Thus, perhaps we could assign a weight of three to each of the single individuals in each group who were assigned to the less likely treatment class, (or alternatively a weight of 1/3 to each of the three individuals in each group who were assigned to the expected class).\n\nThis idea is demonstrated in the image below.\n\n```{r echo = FALSE, fig.align = \"center\"}\nknitr::include_graphics(\"img/causal-inference/propensity-weighting.png\")\n```\n\n\n\n\nAs implied by its name, inverse probability weighting literally refers to weighting the outcome measures by the inverse of the probability of the individual with a given set of covariates being assigned to their treatment (note that this doesn't depend on whether or not the individual *was* in fact assigned to treatment).This quantity is known as the **propensity score** and is denoted\n\n$$p(x) = P(T = 1 | X = x)$$\n\nFor treated individuals, we weight their outcome by\n$$w(x) = \\frac{1}{p(x)},$$\n\nwhereas for control individuals, the weight is:\n\n$$w(x) = \\frac{1}{1 - p(x)}$$\n\n\n\n\nObviously unless we randomly assigned treatment with a set probability (as in the example above), we do not actually know the propensity score of each individual. What we do observe however, is which individuals *were* actually assigned to treatment, along with a number of measured covariates for each individual. The idea is that we can use these covariates as well as our observation of who received treatment to develop a **logistic regression** model that predicts the probability of treatment (propensity score).\n\n\nThus, in the presence of measured confounders, we can estimate the causal effect by IP-weighting the original estimator:\n\n$$\\begin{align*}\n\\hat{\\tau}^{\\textrm{IP}} &= \\frac{1}{n_T}\\sum_{i : T_i = 1} \\frac{Y_i}{\\hat{p}(X_i)} - \\frac{1}{n_C}\\sum_{i:T_i = 0}\\frac{Y_i}{1 - \\hat{p}(X_i)} \\\\\n& = \\frac{1}{n}\\sum_i^n \\frac{T_iY_i}{\\hat{p}(X_i)} -  \\frac{1}{n}\\sum_i^n \\frac{(1 - T_i)Y_i}{1 - \\hat{p}(X_i)}.\n\\end{align*}$$ \n\nwhere $\\hat{p}(x)$ is a logistic-regression based estimator of the propensity score.\n\nTo show that this quantity is unbiased for the original quantity we want to estimate, $\\tau = E[Y(1)] - E[Y(0)]$, it is sufficient to show that\n\n$$E \\left[ \\frac{Y T}{p(X)}\\right] = E[Y(1)], ~~~~~ \\textrm{and} ~~~~~ E \\left[ \\frac{Y (1 - T)}{1 - p(X)}\\right] = E[Y(0)]$$\nwhich is easy to see as follows:\n\n$$\\begin{align*}\nE \\left[ \\frac{Y ~T}{p(X)}\\right] &= E \\left[ E \\left[ \\frac{Y T}{p(X) }\\Bigg| X\\right] \\right]\\\\\n& = E \\left[ E \\left[ \\frac{Y(1) ~T}{p(X)} \\Bigg|X\\right] \\right]\\\\\n& = E \\left[ \\frac{E [ Y(1) |X]~ E[T | X]}{p(X)} \\right]\\\\\n& = E \\left[E [ Y(1) |X] \\right]\\\\\n& = E \\left[ Y(1) \\right]\\\\\n\\end{align*}$$ \n\nand similarly for the second equality.\n\n\n\n## Standardized IP-weighting\n\n\nOne common issue with IP-weighting is that individuals with a propensity score very close to 0 (i.e. those extremely unlikely to be treated) will end up with a horrifyingly large weight, potentially making the weighted estimator highly unstable.\n\nA common alternative to the conventional weights that at least \"kind of\" addresses this problem are the **stabilized weights**, which use the marginal probability of treatment instead of $1$ in the weight numerator.\n\nFor treated individuals, the stabilized weight is given by\n\n$$w(x) = \\frac{P(T = 1)}{p(x)} = \\frac{P(T = 1)}{P(T = 1 | X = x)}$$\n\nand for control individuals, the stabilized weight is \n$$w(x) = \\frac{1 - P(T = 1)}{1 - p(x)} = \\frac{1 - P(T = 1)}{1 - P(T = 1 | X = x)}$$\n\nNote that whereas the original weights essentially [doubles the sample size](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4351790/), these stabilized weights preserve the sample size.\n\n# Resources\n\nMuch of the information provided in this post can be found in the [Causal Inference book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) by Miguel A. Hernan and James M. Robins.\n\nAdditional resources are the books *Causal Inference for Statistics, Social, and Biomedical Sciences* by Guido W. Imbens and Donald B. Rubin, and *Mostly Harmless Econometrics* by Joshua D. Angrist and J&ouml;rn-Steffen Pischke.\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2017-07-05-ip-weighting.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","theme":"simplex","linkcolor":"#6633c4","code-copy":true,"footnotes-hover":true,"title-block-banner":true,"comments":{"utterances":{"repo":"rlbarter/blog_comments"}},"title":"The intuition behind inverse probability weighting in causal inference","author":"Rebecca Barter","categories":["causal inference","statistics"],"date":"2017-07-05","description":"Removing confounding can be done via a variety methods including IP-weighting. This post provides a summary of the intuition behind IP-weighting.","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}